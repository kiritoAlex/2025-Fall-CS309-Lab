"""
ä½¿ç”¨å®˜æ–¹ @modelcontextprotocol/server-filesystem çš„ MCP å®¢æˆ·ç«¯ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•è¿æ¥åˆ° MCP æœåŠ¡å™¨å¹¶ä½¿ç”¨å…¶æä¾›çš„å·¥å…·
"""

import asyncio
import json
import os
from typing import Optional
from contextlib import AsyncExitStack
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from openai import OpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============= MCP å®¢æˆ·ç«¯é…ç½® =============
# å®˜æ–¹æ–‡ä»¶ç³»ç»ŸæœåŠ¡å™¨å‚æ•°
# éœ€è¦å…ˆå®‰è£…: npm install -g @modelcontextprotocol/server-filesystem
server_params = StdioServerParameters(
    command="npx",
    args=[
        "-y",
        "@modelcontextprotocol/server-filesystem",
        "/Users/seven/Project/2025-Fall-CS309-Lab/week4"  # å…è®¸è®¿é—®çš„ç›®å½•
    ]
)

class MCPClient:
    def __init__(self):
        self.exit_stack = AsyncExitStack()
        self.session: Optional[ClientSession] = None
        self.openai = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("BASE_URL")
        )

    async def connect_to_server(self, server_params: StdioServerParameters):
        """è¿æ¥åˆ° MCP æœåŠ¡å™¨"""
        stdio_transport = await self.exit_stack.enter_async_context(
            stdio_client(server_params)
        )
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(
            ClientSession(self.stdio, self.write)
        )

        await self.session.initialize()

        # åˆ—å‡ºå¯ç”¨çš„å·¥å…·
        response = await self.session.list_tools()
        tools = response.tools
        print(f"\nğŸ”§ Connected to MCP server. Available tools: {len(tools)}")
        for tool in tools:
            print(f"   - {tool.name}: {tool.description}")

        return tools

    async def process_query(self, query: str, max_iterations: int = 10):
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨ MCP å·¥å…·"""
        print(f"\n{'='*60}")
        print(f"ğŸ¤– MCP Client with LLM")
        print(f"{'='*60}")
        print(f"ğŸ“ User Query: {query}\n")

        # è·å–å¯ç”¨å·¥å…·å¹¶è½¬æ¢ä¸º OpenAI æ ¼å¼
        response = await self.session.list_tools()
        available_tools = [{
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema
            }
        } for tool in response.tools]

        # åˆå§‹åŒ–æ¶ˆæ¯
        messages = [{"role": "user", "content": query}]

        for iteration in range(max_iterations):
            print(f"\n--- Iteration {iteration + 1} ---")

            # è°ƒç”¨ OpenAI API
            response = self.openai.chat.completions.create(
                model="gpt-5-mini",
                messages=messages,
                tools=available_tools
            )

            message = response.choices[0].message
            print(f"Stop reason: {response.choices[0].finish_reason}")

            # å¦‚æœä¸éœ€è¦å·¥å…·è°ƒç”¨,è¿”å›ç»“æœ
            if response.choices[0].finish_reason == "stop":
                final_response = message.content
                print(f"\nâœ… Final Response:\n{final_response}")
                return final_response

            # å¤„ç†å·¥å…·è°ƒç”¨
            if response.choices[0].finish_reason == "tool_calls" and message.tool_calls:
                # æ·»åŠ  assistant çš„å“åº”åˆ°æ¶ˆæ¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in message.tool_calls
                    ]
                })

                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)

                    print(f"\nğŸ”§ Tool Call:")
                    print(f"   Tool: {tool_name}")
                    print(f"   Arguments: {json.dumps(tool_args, ensure_ascii=False, indent=2)}")

                    # é€šè¿‡ MCP æ‰§è¡Œå·¥å…·
                    result = await self.session.call_tool(tool_name, tool_args)

                    # æå–æ–‡æœ¬å†…å®¹
                    result_text = ""
                    if hasattr(result, 'content') and result.content:
                        if isinstance(result.content, list):
                            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬å†…å®¹
                            result_text = "\n".join(
                                item.text if hasattr(item, 'text') else str(item)
                                for item in result.content
                            )
                        else:
                            result_text = str(result.content)

                    print(f"   Result: {result_text[:200]}...")

                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result_text
                    })

        print("\nâš ï¸  Reached maximum iterations")
        return None

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()

async def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤º MCP å®¢æˆ·ç«¯çš„ä½¿ç”¨"""
    client = MCPClient()

    try:
        # è¿æ¥åˆ°æœåŠ¡å™¨
        print("ğŸ”Œ Connecting to MCP filesystem server...")
        await client.connect_to_server(server_params)

        # æµ‹è¯•æ¡ˆä¾‹ 1: ç®€å•æ–‡ä»¶æ“ä½œ
        print("\n" + "="*60)
        print("æµ‹è¯•æ¡ˆä¾‹ 1: åˆ—å‡ºç›®å½•å†…å®¹")
        print("="*60)
        await client.process_query("åˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶")

        # æµ‹è¯•æ¡ˆä¾‹ 2: è¯»å–æ–‡ä»¶
        print("\n" + "="*60)
        print("æµ‹è¯•æ¡ˆä¾‹ 2: è¯»å–æ–‡ä»¶")
        print("="*60)
        await client.process_query("è¯»å– README.md æ–‡ä»¶å¹¶æ€»ç»“å…¶ä¸»è¦å†…å®¹")

        # æµ‹è¯•æ¡ˆä¾‹ 3: å¤æ‚ä»»åŠ¡
        print("\n" + "="*60)
        print("æµ‹è¯•æ¡ˆä¾‹ 3: å¤šæ­¥éª¤ä»»åŠ¡")
        print("="*60)
        await client.process_query(
            "æ‰¾åˆ°æ‰€æœ‰ .py æ–‡ä»¶ï¼Œè¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œå¹¶å‘Šè¯‰æˆ‘å®ƒçš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆ"
        )

    finally:
        await client.cleanup()

if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())
